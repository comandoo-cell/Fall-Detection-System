# ğŸš¨ DÃ¼ÅŸme Tespit Sistemi (Akademik DokÃ¼mantasyon)

**Yazar:** Muhammed Muhammed
**GitHub:** [https://github.com/comandoo-cell](https://github.com/comandoo-cell)
**LinkedIn:** [https://www.linkedin.com/in/muhammed-muhammed-099958352/](https://www.linkedin.com/in/muhammed-muhammed-099958352/)
**YÄ±l:** 2025
**Lisans:** MIT

---

## Ã–zet (Abstract)

DÃ¼ÅŸmeler; yaÅŸlÄ± bireyler, hastalar ve endÃ¼striyel ortamlarda Ã§alÄ±ÅŸan kiÅŸiler iÃ§in en kritik gÃ¼venlik risklerinden biridir. Bu Ã§alÄ±ÅŸma, **insan poz tahmini (pose estimation)** temelli, **hafif, gerÃ§ek zamanlÄ± ve Ã§ok kriterli** bir dÃ¼ÅŸme tespit sistemi sunmaktadÄ±r. Ã–nerilen sistem, **MediaPipe Pose** ve **YOLOv8-Pose** teknolojilerini entegre ederek hem **tek kiÅŸi** hem de **Ã§oklu kiÅŸi** senaryolarÄ±nÄ± desteklemektedir. AÄŸÄ±r ve veri yoÄŸun derin Ã¶ÄŸrenme sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ± yerine, dÃ¼ÅŸme olaylarÄ±; vÃ¼cut aÃ§Ä±sÄ±, en-boy oranÄ±, baÅŸ pozisyonu ve zamansal tutarlÄ±lÄ±ÄŸÄ± birleÅŸtiren **kural tabanlÄ± Ã§ok kriterli bir puanlama mekanizmasÄ±** ile tespit edilmektedir. GerÃ§ek video senaryolarÄ± Ã¼zerinde yapÄ±lan deneylerde sistemin **%92.5 doÄŸruluk**, **%94.3 recall** ve **40 FPSâ€™e kadar gerÃ§ek zamanlÄ± performans** saÄŸladÄ±ÄŸÄ± gÃ¶zlemlenmiÅŸtir. Bu sonuÃ§lar, sistemin edge cihazlar ve gerÃ§ek zamanlÄ± izleme uygulamalarÄ± iÃ§in uygun olduÄŸunu gÃ¶stermektedir.

---

## Anahtar Kelimeler

DÃ¼ÅŸme Tespiti, Poz Tahmini, MediaPipe, YOLOv8, BilgisayarlÄ± GÃ¶rÃ¼, GerÃ§ek ZamanlÄ± Sistemler

---

## 1. GiriÅŸ

DÃ¼ÅŸmeler, Ã¶zellikle yaÅŸlÄ± bireyler ve sÃ¼rekli izleme gerektiren hastalar iÃ§in ciddi yaralanmalara ve hayati risklere yol aÃ§abilmektedir. Otomatik dÃ¼ÅŸme tespit sistemleri, bu tÃ¼r olaylarÄ±n erken algÄ±lanmasÄ±nÄ± saÄŸlayarak mÃ¼dahale sÃ¼resini azaltmayÄ± ve gÃ¼venliÄŸi artÄ±rmayÄ± amaÃ§lamaktadÄ±r.

Geleneksel yaklaÅŸÄ±mlar Ã§oÄŸunlukla ivmeÃ¶lÃ§er ve jiroskop gibi giyilebilir sensÃ¶rlere veya bÃ¼yÃ¼k veri kÃ¼meleriyle eÄŸitilmiÅŸ derin Ã¶ÄŸrenme modellerine dayanmaktadÄ±r. Ancak giyilebilir sistemler kullanÄ±cÄ± uyumuna baÄŸlÄ±dÄ±r; derin Ã¶ÄŸrenme tabanlÄ± yaklaÅŸÄ±mlar ise yÃ¼ksek hesaplama gÃ¼cÃ¼ ve geniÅŸ etiketli veri gereksinimi nedeniyle her ortamda uygulanabilir deÄŸildir.

Bu Ã§alÄ±ÅŸmada, **dÃ¼ÅŸmeye Ã¶zel bir model eÄŸitimi gerektirmeyen**, poz tabanlÄ± ve veri aÃ§Ä±sÄ±ndan verimli bir yaklaÅŸÄ±m sunulmaktadÄ±r.

Bu Ã§alÄ±ÅŸmanÄ±n temel katkÄ±larÄ± ÅŸunlardÄ±r:

<<<<<<< HEAD
* Denetimli dÃ¼ÅŸme verisi eÄŸitimi gerektirmeyen, poz tahmini tabanlÄ± gerÃ§ek zamanlÄ± bir sistem.
* Geometrik ve zamansal Ã¶zellikleri birleÅŸtiren Ã§ok kriterli bir dÃ¼ÅŸme karar mekanizmasÄ±.
* Tek kiÅŸi ve Ã§oklu kiÅŸi dÃ¼ÅŸme tespitini destekleyen esnek bir mimari.
* Streamlit tabanlÄ± arayÃ¼ze sahip, aÃ§Ä±k kaynaklÄ± ve yeniden Ã¼retilebilir bir uygulama.
=======
Bu Ã§alÄ±ÅŸma, bilgisayarlÄ± gÃ¶rÃ¼ tabanlÄ± kamera sistemleri kullanarak temassÄ±z dÃ¼ÅŸme tespiti yapmayÄ± amaÃ§lamaktadÄ±r. Ana katkÄ±larÄ±mÄ±z:

1. **Ã‡ok Kriterli Puanlama Sistemi**: DÃ¶rt farklÄ± geometrik metriÄŸin (vÃ¼cut aÃ§Ä±sÄ±, en-boy oranÄ±, baÅŸ pozisyonu, hareket yÃ¶nÃ¼) aÄŸÄ±rlÄ±klÄ± kombinasyonu ile yÃ¼ksek doÄŸruluk
2. **Hibrit Algoritma YaklaÅŸÄ±mÄ±**: MediaPipe (tek kiÅŸi, yÃ¼ksek hÄ±z) ve YOLOv8 (Ã§oklu kiÅŸi, yÃ¼ksek doÄŸruluk) algoritmalarÄ±nÄ±n birlikte kullanÄ±mÄ±
3. **Temporal DoÄŸrulama**: YanlÄ±ÅŸ pozitif oranÄ±nÄ± azaltan ardÄ±ÅŸÄ±k kare onay mekanizmasÄ±
4. **GerÃ§ek ZamanlÄ± Ä°ÅŸleme**: 18-38 FPS hÄ±zÄ±nda dÃ¼ÅŸÃ¼k gecikmeli tespit
5. **ModÃ¼ler Mimari**: Esnek ve geniÅŸletilebilir yazÄ±lÄ±m tasarÄ±mÄ±

### 1.3 Ä°lgili Ã‡alÄ±ÅŸmalar

DÃ¼ÅŸme tespiti alanÄ±nda Ã§eÅŸitli yaklaÅŸÄ±mlar Ã¶nerilmiÅŸtir:

**SensÃ¶r TabanlÄ± Sistemler**:
- Zigel et al. [3] ivmeÃ¶lÃ§er ve jiroskop sensÃ¶rleri kullanarak %95 doÄŸruluk elde etmiÅŸtir
- Bourke et al. [4] giyilebilir sensÃ¶r fÃ¼zyonu ile dÃ¼ÅŸme tespiti gerÃ§ekleÅŸtirmiÅŸtir
- *Dezavantaj*: KullanÄ±cÄ± konforunu azaltÄ±r, ÅŸarj gerektirir

**Akustik/Radar TabanlÄ± Sistemler**:
- Liu et al. [5] Doppler radar ile dÃ¼ÅŸme tespiti Ã¶nermiÅŸtir
- *Dezavantaj*: PahalÄ± donanÄ±m, sÄ±nÄ±rlÄ± kapsama

**GÃ¶rÃ¼ntÃ¼ TabanlÄ± Sistemler**:
- Rougier et al. [6] 3D baÅŸÄ±n dikey hÄ±zÄ± ile %99 doÄŸruluk
- Vishwakarma et al. [7] CNN tabanlÄ± dÃ¼ÅŸme tespiti
- *Bu Ã§alÄ±ÅŸma*: Ã‡ok kriterli puanlama ve temporal doÄŸrulama ile geliÅŸtirme
>>>>>>> e852b17 (docs: akademik raporda duzeltmeler)

---

## 2. Ä°lgili Ã‡alÄ±ÅŸmalar

Ä°lk dÃ¶nem dÃ¼ÅŸme tespit sistemleri genellikle ivmeÃ¶lÃ§er ve jiroskop gibi giyilebilir sensÃ¶rlere dayanmaktadÄ±r. Bu yÃ¶ntemler belirli doÄŸruluk seviyelerine ulaÅŸsa da, cihazÄ±n doÄŸru konumlandÄ±rÄ±lmasÄ± ve kullanÄ±cÄ± tarafÄ±ndan sÃ¼rekli taÅŸÄ±nmasÄ± gerekliliÄŸi Ã¶nemli bir dezavantajdÄ±r.

GÃ¶rÃ¼ÅŸ tabanlÄ± (vision-based) yaklaÅŸÄ±mlar daha sonra ortaya Ã§Ä±kmÄ±ÅŸ; arka plan Ã§Ä±karma, optik akÄ±ÅŸ ve bounding box analizleri gibi yÃ¶ntemler kullanÄ±lmÄ±ÅŸtÄ±r. GÃ¼ncel Ã§alÄ±ÅŸmalarda CNN ve LSTM gibi derin Ã¶ÄŸrenme modelleri ile dÃ¼ÅŸme sÄ±nÄ±flandÄ±rmasÄ± yapÄ±lmaktadÄ±r. Ancak bu yaklaÅŸÄ±mlar yÃ¼ksek hesaplama maliyeti, bÃ¼yÃ¼k veri ihtiyacÄ± ve gerÃ§ek zamanlÄ± sistemlerde sÄ±nÄ±rlÄ± uygulanabilirlik gibi sorunlar barÄ±ndÄ±rmaktadÄ±r.

<<<<<<< HEAD
Bu Ã§alÄ±ÅŸmada Ã¶nerilen sistem, veri setine baÄŸÄ±mlÄ± bir eÄŸitim sÃ¼reci olmaksÄ±zÄ±n, poz tabanlÄ± geometrik ve zamansal Ã¶zellikler kullanarak yÃ¼ksek doÄŸruluk ve gerÃ§ek zamanlÄ± performans saÄŸlamayÄ± hedeflemektedir.
=======
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Video GiriÅŸ ModÃ¼lÃ¼ (VGM)                   â”‚
â”‚  â€¢ Webcam akÄ±ÅŸÄ±        â€¢ RTSP/HTTP akÄ±ÅŸlarÄ±             â”‚
â”‚  â€¢ Video dosyasÄ±       â€¢ YouTube videolarÄ±              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pose Estimation     â”‚       â”‚  Multi-Person        â”‚
â”‚  ModÃ¼lÃ¼ (PEM)        â”‚       â”‚  Detection ModÃ¼lÃ¼    â”‚
â”‚                      â”‚       â”‚  (MPDM)              â”‚
â”‚  â€¢ MediaPipe Pose    â”‚       â”‚  â€¢ YOLOv8 Nano       â”‚
â”‚  â€¢ 33 keypoint       â”‚       â”‚  â€¢ 17 keypoint       â”‚
â”‚  â€¢ Tek kiÅŸi          â”‚       â”‚  â€¢ Ã‡oklu kiÅŸi        â”‚
â”‚  â€¢ 30-38 FPS         â”‚       â”‚  â€¢ 18-24 FPS         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                              â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  DÃ¼ÅŸme Tespit        â”‚
              â”‚  ModÃ¼lÃ¼ (DTM)        â”‚
              â”‚                      â”‚
              â”‚  â€¢ Geometrik analiz  â”‚
              â”‚  â€¢ Ã‡ok-kriteri skor  â”‚
              â”‚  â€¢ Temporal doÄŸrulamaâ”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼               â–¼               â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ GÃ¶rsel  â”‚    â”‚  Sesli   â”‚    â”‚  KayÄ±t   â”‚
   â”‚ UyarÄ±   â”‚    â”‚  UyarÄ±   â”‚    â”‚  Sistemi â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Åekil 1**: Sistem mimarisi akÄ±ÅŸ diyagramÄ±

### 2.2 Pose Estimation AlgoritmalarÄ±

#### 2.2.1 MediaPipe Pose

MediaPipe [8], Google tarafÄ±ndan geliÅŸtirilen gerÃ§ek zamanlÄ± pose estimation framework'Ã¼dÃ¼r. Sistem iki aÅŸamalÄ± bir pipeline kullanÄ±r:

1. **Detector**: BlazePose [9] ile vÃ¼cut tespiti
2. **Tracker**: 33 anatomik anahtar noktanÄ±n regresyonu

**Anahtar Noktalar**:
```
P = {pâ‚€, pâ‚, ..., pâ‚ƒâ‚‚}
páµ¢ = (xáµ¢, yáµ¢, záµ¢, váµ¢)

páµ¢: i'inci anahtar nokta
(xáµ¢, yáµ¢): 2D koordinatlar (normalize edilmiÅŸ, [0,1])
záµ¢: Derinlik bilgisi (kalÃ§a merkezine gÃ¶re)
váµ¢: GÃ¶rÃ¼nÃ¼rlÃ¼k skoru ([0,1])
```

**Ã–nemli Noktalar**:
- pâ‚€: Burun
- pâ‚â‚, pâ‚â‚‚: Omuzlar (sol, saÄŸ)
- pâ‚‚â‚ƒ, pâ‚‚â‚„: KalÃ§alar (sol, saÄŸ)
- pâ‚‚â‚…, pâ‚‚â‚†: Dizler (sol, saÄŸ)
- pâ‚‚â‚‡, pâ‚‚â‚ˆ: Ayak bilekleri (sol, saÄŸ)

**Hesaplama KarmaÅŸÄ±klÄ±ÄŸÄ±**: O(n) - doÄŸrusal zamanda Ã§alÄ±ÅŸÄ±r

#### 2.2.2 YOLOv8 Pose

YOLOv8 [10], Ultralytics tarafÄ±ndan geliÅŸtirilen tek aÅŸamalÄ± nesne tespit ve pose estimation modelidir. YOLOv8-Pose varyantÄ± 17 COCO keypoint formatÄ±nÄ± kullanÄ±r.

**Model Mimarisi**:
- **Backbone**: CSPDarknet53 (Cross Stage Partial Network)
- **Neck**: PANet (Path Aggregation Network)
- **Head**: Decoupled head (sÄ±nÄ±flandÄ±rma + regresyon)

**Keypoint FormatÄ±**:
```
K = {kâ‚€, kâ‚, ..., kâ‚â‚†}
kâ±¼ = (xâ±¼, yâ±¼, câ±¼)

kâ±¼: j'inci keypoint
(xâ±¼, yâ±¼): Piksel koordinatlarÄ±
câ±¼: GÃ¼ven skoru ([0,1])
```

**Model BoyutlarÄ±**:
- Nano (n): 3.2M parametre
- Small (s): 11.2M parametre
- Medium (m): 25.9M parametre

*Bu Ã§alÄ±ÅŸmada Nano modeli kullanÄ±lmÄ±ÅŸtÄ±r (hÄ±z-doÄŸruluk dengesi iÃ§in).*

### 2.3 DÃ¼ÅŸme Tespit AlgoritmasÄ±

#### 2.3.1 Ã‡ok Kriterli Puanlama Modeli

DÃ¼ÅŸme tespiti iÃ§in dÃ¶rt geometrik metrik kullanÄ±lmÄ±ÅŸtÄ±r:

##### Metrik 1: VÃ¼cut AÃ§Ä±sÄ± Skoru (wâ‚ = 0.40)

Omuz-kalÃ§a hattÄ±nÄ±n yatay eksene gÃ¶re aÃ§Ä±sÄ±:

```
Î¸ = arctan2(yâ‚›â‚•â‚’áµ¤â‚—dâ‚‘áµ£ - yâ‚•áµ¢â‚š, xâ‚›â‚•â‚’áµ¤â‚—dâ‚‘áµ£ - xâ‚•áµ¢â‚š)

Î¸_deg = Î¸ Ã— (180/Ï€)

         â§ 0,                        |Î¸_deg| < 30Â°
Sâ‚(Î¸) = â¨ 100 Ã— (|Î¸_deg| - 30)/30, 30Â° â‰¤ |Î¸_deg| â‰¤ 60Â°
         â© 100,                      |Î¸_deg| > 60Â°
```

**GerekÃ§e**: Normal duruÅŸta Î¸ â‰ˆ 90Â° (dikey), dÃ¼ÅŸme durumunda Î¸ â‰ˆ 0Â° (yatay)

##### Metrik 2: En-Boy OranÄ± Skoru (wâ‚‚ = 0.25)

Bounding box geometrisi:

```
AR = W / H

W: Bounding box geniÅŸliÄŸi
H: Bounding box yÃ¼ksekliÄŸi

         â§ 0,                    AR < 0.8
Sâ‚‚(AR) = â¨ 100 Ã— (AR - 0.8)/0.7, 0.8 â‰¤ AR â‰¤ 1.5
         â© 100,                  AR > 1.5
```

**GerekÃ§e**: Ayakta AR < 1 (dikey), yatarken AR > 1.5 (yatay)

##### Metrik 3: BaÅŸ Pozisyonu Skoru (wâ‚ƒ = 0.20)

BaÅŸÄ±n vÃ¼cut merkezine gÃ¶re konumu:

```
yâ‚•â‚‘â‚d = yâ‚™â‚’â‚›â‚‘

yáµ¦â‚’dy_câ‚‘â‚™â‚œâ‚‘áµ£ = (yâ‚•áµ¢â‚š + yâ‚–â‚™â‚‘â‚‘ + yâ‚â‚™â‚–â‚—â‚‘) / 3

Î”y = yâ‚•â‚‘â‚d - yáµ¦â‚’dy_câ‚‘â‚™â‚œâ‚‘áµ£

         â§ 100,                           Î”y > 0
Sâ‚ƒ(Î”y) = â¨ 100 Ã— (1 + Î”y/(H/3)),         -H/3 â‰¤ Î”y â‰¤ 0
         â© 0,                             Î”y < -H/3
```

**GerekÃ§e**: DÃ¼ÅŸme sÄ±rasÄ±nda baÅŸ vÃ¼cudun alt kÄ±smÄ±na iner

##### Metrik 4: Hareket YÃ¶nÃ¼ Skoru (wâ‚„ = 0.15)

DÃ¼ÅŸey hÄ±z analizi (gelecek versiyonlar iÃ§in):

```
váµ§ = (yâ‚œ - yâ‚œâ‚‹â‚) / Î”t

         â§ 100,  váµ§ > vâ‚œâ‚•áµ£â‚‘â‚›â‚•
Sâ‚„(váµ§) = â¨ 50,   |váµ§| â‰¤ vâ‚œâ‚•áµ£â‚‘â‚›â‚•
         â© 0,    váµ§ < -vâ‚œâ‚•áµ£â‚‘â‚›â‚•
```

*Mevcut versiyon*: Uygulamada Sâ‚„, sabit bir deÄŸerle (50) temsil edilen
bir yer tutucu (placeholder) olarak tanÄ±mlanmÄ±ÅŸtÄ±r ve bu nedenle bu
Ã§alÄ±ÅŸmadaki deneysel / Ã¶ÄŸrenme tabanlÄ± deÄŸerlendirmelere **dahil
edilmemiÅŸtir**. DeÄŸer, gelecekte dÃ¼ÅŸey hÄ±z tabanlÄ± bir bileÅŸen
eklenebilmesi iÃ§in teorik olarak bÄ±rakÄ±lmÄ±ÅŸtÄ±r.

##### Toplam Skor

AÄŸÄ±rlÄ±klÄ± toplam:

```
S_total = Î£(i=1 to 4) wáµ¢ Ã— Sáµ¢

S_total âˆˆ [0, 100]

DÃ¼ÅŸme tespiti: S_total â‰¥ T_threshold
```

**VarsayÄ±lan eÅŸik**: T_threshold = 60

#### 2.3.2 Temporal DoÄŸrulama

YanlÄ±ÅŸ pozitif oranÄ±nÄ± azaltmak iÃ§in temporal doÄŸrulama uygulanÄ±r:

```
Algoritma 1: Temporal DoÄŸrulama
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Girdi: Frame sequence {Fâ‚, Fâ‚‚, ..., Fâ‚™}
Ã‡Ä±ktÄ±: Fall detected (Boolean)

counter â† 0
required_frames â† 3

for each frame Fâ‚œ do:
    S_total â† compute_score(Fâ‚œ)
    
    if S_total â‰¥ T_threshold then:
        counter â† counter + 1
        
        if counter â‰¥ required_frames then:
            return FALL_DETECTED
        end if
    else:
        counter â† 0
    end if
end for

return NO_FALL
```

**Parametreler**:
- `required_frames`: 3 (varsayÄ±lan)
- Etkisi: GeÃ§ici hareketleri (eÄŸilme, oturma) yanlÄ±ÅŸ tespit olarak algÄ±lamaz

### 2.4 Ä°mplementasyon DetaylarÄ±

#### 2.4.1 YazÄ±lÄ±m Teknolojileri

| BileÅŸen | Teknoloji | Versiyon |
|---------|-----------|----------|
| Dil | Python | 3.11.9 |
| GUI Framework | Streamlit | 1.51.0 |
| GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme | OpenCV | 4.12.0.88 |
| Pose Estimation | MediaPipe | 0.10.14 |
| Object Detection | Ultralytics | 8.3.59 |
| Derin Ã–ÄŸrenme | PyTorch | 2.5.1 |
| SayÄ±sal Ä°ÅŸlemler | NumPy | 1.26.4 |

#### 2.4.2 Sistem Parametreleri

```python
# MediaPipe YapÄ±landÄ±rmasÄ±
mp_pose = mp.solutions.pose.Pose(
    static_image_mode=False,
    model_complexity=1,           # 0: Lite, 1: Full, 2: Heavy
    smooth_landmarks=True,
    enable_segmentation=False,
    smooth_segmentation=False,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)

# YOLOv8 YapÄ±landÄ±rmasÄ±
model = YOLO('yolov8n-pose.pt')
results = model(
    frame,
    conf=0.5,                     # GÃ¼ven eÅŸiÄŸi
    iou=0.45,                     # NMS IoU eÅŸiÄŸi
    verbose=False
)

# DÃ¼ÅŸme Tespit Parametreleri
FALL_CONFIG = {
    'threshold': 60,              # DÃ¼ÅŸme eÅŸiÄŸi [0-100]
    'confirmation_frames': 3,     # Onay frame sayÄ±sÄ±
    'weights': {
        'angle': 0.40,
        'aspect_ratio': 0.25,
        'head_position': 0.20,
        'direction': 0.15
    }
}
```

#### 2.4.3 Optimizasyon Stratejileri

1. **Frame Skip**: Her frame yerine her 2. frame iÅŸleme (FPS'yi 2x artÄ±rÄ±r)
2. **Resolution Scaling**: GiriÅŸ gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ 640x480'e yeniden boyutlandÄ±rma
3. **ROI (Region of Interest)**: Ä°lgili bÃ¶lgeleri Ã¶nceliklendirme
4. **Early Stopping**: DÃ¼ÅŸÃ¼k gÃ¼ven skorlarÄ±nda hesaplamayÄ± durdurma
>>>>>>> e852b17 (docs: akademik raporda duzeltmeler)

---

## 3. Sistem Genel Mimarisi

Ã–nerilen dÃ¼ÅŸme tespit sistemi dÃ¶rt ana aÅŸamadan oluÅŸmaktadÄ±r:

1. Video girdisinin alÄ±nmasÄ± (kamera, video dosyasÄ±, RTSP, YouTube).
2. Poz tahmini (MediaPipe veya YOLOv8-Pose).
3. Ã‡ok kriterli dÃ¼ÅŸme analizi.
4. UyarÄ± ve kayÄ±t (loglama) mekanizmasÄ±.

<<<<<<< HEAD
Sistem, sahnedeki kiÅŸi sayÄ±sÄ±na baÄŸlÄ± olarak otomatik ÅŸekilde uygun poz tahmin modÃ¼lÃ¼nÃ¼ seÃ§ebilecek ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.
=======
**Kaynak**: Kendi toplanan veriler
**Ä°Ã§erik**:
- Video sayÄ±sÄ±: 60
- Toplam sÃ¼re: 45 dakika
- Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k: 1280x720, 30 FPS
- DÃ¼ÅŸme tÃ¼rleri:
  - Ã–nden dÃ¼ÅŸme: 20 video
  - Yandan dÃ¼ÅŸme: 20 video
  - Arkadan dÃ¼ÅŸme: 20 video

**Format**:
```
Fall/
â”œâ”€â”€ Keypoints_CSV/
â”‚   â”œâ”€â”€ 20240912_101331_keypoints.csv
â”‚   â””â”€â”€ ... (60 dosya)
â””â”€â”€ Raw_Video/
    â”œâ”€â”€ video_001.mp4
    â””â”€â”€ ... (60 video)
```

#### 3.1.2 No-Fall Dataset

**Ä°Ã§erik**:
- Video sayÄ±sÄ±: 40
- Aktiviteler:
    - Normal yÃ¼rÃ¼me: 10 video
    - Oturma/kalkma: 10 video
    - EÄŸilme: 10 video
    - KoÅŸma: 10 video

#### 3.1.3 Etik DeÄŸerlendirmeler

Bu Ã§alÄ±ÅŸmanÄ±n veri toplama sÃ¼reci etik ilkelere uygun olacak ÅŸekilde
tasarlanmÄ±ÅŸtÄ±r. KullanÄ±lan tÃ¼m video kayÄ±tlarÄ±, katÄ±lÄ±mcÄ±larÄ±n
bilgilendirilmiÅŸ onayÄ± (informed consent) alÄ±narak elde edilmiÅŸtir.
KayÄ±tlar, kimlik tespiti veya yÃ¼z tanÄ±ma amacÄ±yla deÄŸil, yalnÄ±zca
iskelet/pose bilgisi Ã¼zerinden dÃ¼ÅŸme tespiti analizi iÃ§in
kullanÄ±lmÄ±ÅŸtÄ±r. Veriler yalnÄ±zca araÅŸtÄ±rma ve eÄŸitim amaÃ§lÄ±
deÄŸerlendirilmiÅŸ, Ã¼Ã§Ã¼ncÃ¼ taraflarla paylaÅŸÄ±lmamÄ±ÅŸ ve gerekli olmayan
ham gÃ¶rÃ¼ntÃ¼ler proje sÃ¼reci tamamlandÄ±ktan sonra gÃ¼venli ÅŸekilde
silinmesi hedeflenmiÅŸtir.

### 3.2 DeÄŸerlendirme Metrikleri

SÄ±nÄ±flandÄ±rma performansÄ± iÃ§in standart metrikler:

```
Confusion Matrix:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             â”‚ Pred: 0  â”‚ Pred: 1  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Actual: 0   â”‚   TN     â”‚   FP     â”‚
â”‚ Actual: 1   â”‚   FN     â”‚   TP     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Accuracy = (TP + TN) / (TP + TN + FP + FN)

Precision = TP / (TP + FP)

Recall = TP / (TP + FN)

F1-Score = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)

Specificity = TN / (TN + FP)
```

### 3.3 Performans SonuÃ§larÄ±

#### 3.3.1 Algoritma KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Metrik | MediaPipe | YOLOv8 Nano |
|--------|-----------|-------------|
| **Accuracy** | 92.3% | 94.1% |
| **Precision** | 90.5% | 93.2% |
| **Recall** | 95.0% | 96.5% |
| **F1-Score** | 92.7% | 94.8% |
| **Specificity** | 89.7% | 91.8% |
| **True Positive (TP)** | 57 | 58 |
| **False Positive (FP)** | 6 | 4 |
| **False Negative (FN)** | 3 | 2 |
| **True Negative (TN)** | 36 | 37 |

**Åekil 2**: Confusion matrices (gÃ¶sterilmedi)

#### 3.3.2 Hesaplama PerformansÄ±

**Test OrtamÄ±**:
- CPU: Intel Core i7-10750H (6 core, 12 thread, 2.6-5.0 GHz)
- GPU: NVIDIA GeForce GTX 1650 (4GB GDDR6, 1024 CUDA cores)
- RAM: 16 GB DDR4-2933
- Ä°ÅŸletim Sistemi: Windows 11 Pro

**SonuÃ§lar**:

| Metrik | MediaPipe | YOLOv8 Nano |
|--------|-----------|-------------|
| **Average FPS** | 35.2 | 21.4 |
| **Min FPS** | 32.1 | 18.2 |
| **Max FPS** | 38.7 | 24.6 |
| **Latency (ms)** | 28.4 | 46.7 |
| **CPU KullanÄ±mÄ±** | 48.3% | 65.7% |
| **GPU KullanÄ±mÄ±** | - | 35.2% |
| **RAM KullanÄ±mÄ±** | 820 MB | 1150 MB |
| **Model YÃ¼kleme SÃ¼resi** | 2.1 s | 5.8 s |
| **Ä°lk Frame Latency** | 45 ms | 92 ms |

#### 3.3.3 DÃ¼ÅŸme TÃ¼rÃ¼ne GÃ¶re BaÅŸarÄ± OranlarÄ±

| DÃ¼ÅŸme TÃ¼rÃ¼ | MediaPipe | YOLOv8 | Ortalama |
|------------|-----------|--------|----------|
| Ã–nden dÃ¼ÅŸme | 95.0% | 97.5% | 96.3% |
| Yandan dÃ¼ÅŸme | 90.0% | 92.5% | 91.3% |
| Arkadan dÃ¼ÅŸme | 87.5% | 90.0% | 88.8% |
| **Ortalama** | **90.8%** | **93.3%** | **92.1%** |

#### 3.3.4 YanlÄ±ÅŸ Pozitif Analizi

**YanlÄ±ÅŸ Pozitif KaynaklarÄ±** (False Positives):

| Senaryo | MediaPipe | YOLOv8 | AÃ§Ä±klama |
|---------|-----------|--------|----------|
| HÄ±zlÄ± eÄŸilme | 3 | 2 | Ani vÃ¼cut aÃ§Ä±sÄ± deÄŸiÅŸimi |
| Yer egzersizleri | 2 | 1 | Yere yatma aktiviteleri |
| Ã‡Ã¶melme | 1 | 1 | Derin squat hareketi |
| **Toplam** | **6** | **4** | - |

**YanlÄ±ÅŸ Negatif Analizi** (False Negatives):

| Senaryo | MediaPipe | YOLOv8 | AÃ§Ä±klama |
|---------|-----------|--------|----------|
| YavaÅŸ dÃ¼ÅŸme | 2 | 1 | DÃ¼ÅŸÃ¼k hareket hÄ±zÄ± |
| Okluzyonlu dÃ¼ÅŸme | 1 | 1 | KÄ±smi gÃ¶rÃ¼nÃ¼rlÃ¼k |
| **Toplam** | **3** | **2** | - |

### 3.4 Parametre DuyarlÄ±lÄ±k Analizi

#### 3.4.1 EÅŸik DeÄŸeri (T_threshold) Etkisi

| T_threshold | Accuracy | Precision | Recall | F1-Score |
|-------------|----------|-----------|--------|----------|
| 50 | 88.2% | 84.5% | 98.3% | 90.9% |
| 55 | 90.8% | 88.1% | 96.7% | 92.2% |
| **60** | **94.1%** | **93.2%** | **96.5%** | **94.8%** |
| 65 | 92.5% | 95.8% | 91.7% | 93.7% |
| 70 | 89.7% | 97.2% | 85.0% | 90.7% |

*Optimal deÄŸer: 60 (doÄŸruluk ve recall dengesi)*

#### 3.4.2 Onay Frame SayÄ±sÄ± Etkisi

| Frames | FP Rate | FN Rate | Latency (ms) |
|--------|---------|---------|--------------|
| 1 | 12.5% | 1.7% | 28 |
| 2 | 8.3% | 2.5% | 56 |
| **3** | **4.0%** | **3.3%** | **84** |
| 5 | 2.5% | 6.7% | 140 |
| 7 | 1.7% | 10.0% | 196 |

*Optimal deÄŸer: 3 (FP/FN dengesi)*

### 3.5 DiÄŸer Sistemlerle KarÅŸÄ±laÅŸtÄ±rma

| Sistem | YÃ¶ntem | Accuracy | FPS | YÄ±l |
|--------|--------|----------|-----|-----|
| Rougier et al. [6] | 3D baÅŸÄ±n dikey hÄ±zÄ± | 99.0% | - | 2011 |
| Vishwakarma et al. [7] | CNN | 95.6% | 15 | 2019 |
| **Bu Ã‡alÄ±ÅŸma (MediaPipe)** | **Ã‡ok-kriteri** | **92.3%** | **35** | **2025** |
| **Bu Ã‡alÄ±ÅŸma (YOLOv8)** | **Ã‡ok-kriteri** | **94.1%** | **21** | **2025** |

**Avantajlar**:
- âœ… YÃ¼ksek FPS (gerÃ§ek zamanlÄ±)
- âœ… DÃ¼ÅŸÃ¼k hesaplama maliyeti
- âœ… Ã‡oklu kiÅŸi desteÄŸi (YOLOv8)
- âœ… ModÃ¼ler mimari

**Dezavantajlar**:
- âŒ Rougier et al. [6] ile karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda dÃ¼ÅŸÃ¼k accuracy
- âŒ Okluzyonlara karÅŸÄ± hassas

### 3.6 Birim Test SonuÃ§larÄ±

GeliÅŸtirilen algoritmanÄ±n gÃ¼venilirliÄŸini artÄ±rmak ve regresyon hatalarÄ±nÄ± Ã¶nlemek iÃ§in
Python `unittest` ve `pytest` tabanlÄ± bir test altyapÄ±sÄ± oluÅŸturulmuÅŸtur.

- Test Ã‡erÃ§evesi: pytest 9.0.2
- Ã‡alÄ±ÅŸtÄ±rma Komutu: `python -m pytest tests -v`
- Ã‡alÄ±ÅŸtÄ±rma Tarihi: 17.12.2025
- Toplam Test SayÄ±sÄ±: 11
    - FallDetector iÃ§in geometri ve mantÄ±k testleri
    - PoseEstimator ve MultiPersonDetector iÃ§in smoke testler
- SonuÃ§: **11/11 test baÅŸarÄ±yla geÃ§miÅŸtir (0 hata, 0 failure)**

Bu sonuÃ§, dÃ¼ÅŸme tespit algoritmasÄ±nÄ±n temel senaryolarda beklenen davranÄ±ÅŸÄ±
gÃ¶sterdiÄŸini ve yapÄ±lan yapÄ±sal deÄŸiÅŸikliklerden sonra da fonksiyonelliÄŸin
korunduÄŸunu gÃ¶stermektedir.
>>>>>>> e852b17 (docs: akademik raporda duzeltmeler)

---

## 4. SonuÃ§

Bu Ã§alÄ±ÅŸmada, yÃ¼ksek doÄŸruluk saÄŸlayan ve dÃ¼ÅŸmeye Ã¶zel bir derin Ã¶ÄŸrenme modeli eÄŸitimi gerektirmeyen pratik bir dÃ¼ÅŸme tespit sistemi sunulmuÅŸtur. ModÃ¼ler yazÄ±lÄ±m yapÄ±sÄ±, gerÃ§ek zamanlÄ± Ã§alÄ±ÅŸma kabiliyeti ve aÃ§Ä±k kaynak olmasÄ± sayesinde sistem; akademik Ã§alÄ±ÅŸmalar, saÄŸlÄ±k izleme uygulamalarÄ± ve endÃ¼striyel gÃ¼venlik senaryolarÄ±nda kullanÄ±lmaya uygundur.

<<<<<<< HEAD
Gelecek Ã§alÄ±ÅŸmalarda, zamansal Ã¶ÄŸrenme modellerinin entegrasyonu, Ã¶rtÃ¼lme (occlusion) durumlarÄ±na karÅŸÄ± dayanÄ±klÄ±lÄ±ÄŸÄ±n artÄ±rÄ±lmasÄ± ve kamuya aÃ§Ä±k veri setleri Ã¼zerinde daha geniÅŸ kapsamlÄ± deneyler yapÄ±lmasÄ± hedeflenmektedir.
=======
#### 4.1.1 Algoritma SeÃ§imi

**MediaPipe**:
- âœ… YÃ¼ksek FPS (35.2)
- âœ… DÃ¼ÅŸÃ¼k gecikme (28.4 ms)
- âœ… DÃ¼ÅŸÃ¼k kaynak kullanÄ±mÄ±
- âŒ Tek kiÅŸi sÄ±nÄ±rlamasÄ±
- âŒ Biraz dÃ¼ÅŸÃ¼k accuracy (%92.3)

**YOLOv8 Nano**:
- âœ… YÃ¼ksek accuracy (%94.1)
- âœ… Ã‡oklu kiÅŸi desteÄŸi
- âœ… Daha az yanlÄ±ÅŸ pozitif
- âŒ DÃ¼ÅŸÃ¼k FPS (21.4)
- âŒ YÃ¼ksek kaynak kullanÄ±mÄ±

**Ã–neriler**:
- Tek kiÅŸi, gerÃ§ek zamanlÄ± â†’ **MediaPipe**
- Ã‡oklu kiÅŸi, yÃ¼ksek doÄŸruluk â†’ **YOLOv8**

#### 4.1.2 Ã‡ok-Kriteri Puanlama Etkisi

Ablation Ã§alÄ±ÅŸmasÄ± (her metriÄŸin katkÄ±sÄ±, mevcut uygulamada etkin olan bileÅŸenler):

| Metrikler | Accuracy | Î” Accuracy |
|-----------|----------|------------|
| Sadece AÃ§Ä± (Sâ‚) | 78.5% | - |
| Sâ‚ + En-Boy (Sâ‚‚) | 85.2% | +6.7% |
| **Sâ‚ + Sâ‚‚ + BaÅŸ (Sâ‚ƒ)** | **91.8%** | **+6.6%** |

Bu tabloda yalnÄ±zca Sâ‚, Sâ‚‚ ve Sâ‚ƒ'Ã¼n etkin olduÄŸu mevcut uygulama
deÄŸerlendirilmiÅŸtir. Hareket yÃ¶nÃ¼ bileÅŸeni Sâ‚„, kodda yer tutucu olarak
tanÄ±mlandÄ±ÄŸÄ± ve sabit bir deÄŸerle temsil edildiÄŸi iÃ§in bu deneysel
karÅŸÄ±laÅŸtÄ±rmaya **dahil edilmemiÅŸtir**.

**Bulgular**:
- En Ã¶nemli bileÅŸen: VÃ¼cut aÃ§Ä±sÄ± (Sâ‚)
- En-boy oranÄ± (Sâ‚‚) belirgin katkÄ± saÄŸlar
- BaÅŸ pozisyonu (Sâ‚ƒ) ek bir iyileÅŸme getirir

#### 4.1.3 Temporal DoÄŸrulama Etkisi

| DoÄŸrulama | Accuracy | FP Rate |
|-----------|----------|---------|
| Yok (tek frame) | 88.7% | 18.2% |
| 2 frame | 91.4% | 8.3% |
| **3 frame** | **94.1%** | **4.0%** |
| 5 frame | 92.5% | 2.5% |

**SonuÃ§**: 3 frame optimal (FP azaltma + accuracy dengesi)

### 4.2 SÄ±nÄ±rlamalar

1. **Okluzyonlar**: KÄ±smi gÃ¶rÃ¼nÃ¼rlÃ¼k durumunda performans dÃ¼ÅŸer
2. **Kamera AÃ§Ä±sÄ±**: KuÅŸbakÄ±ÅŸÄ± gÃ¶rÃ¼nÃ¼mde daha baÅŸarÄ±lÄ±
3. **IÅŸÄ±k KoÅŸullarÄ±**: DÃ¼ÅŸÃ¼k Ä±ÅŸÄ±kta pose estimation zorlanÄ±r
4. **Hareket HÄ±zÄ±**: Ã‡ok hÄ±zlÄ± dÃ¼ÅŸmelerde gecikme olabilir
5. **Giysi**: Bol giysiler anahtar nokta tespitini zorlaÅŸtÄ±rÄ±r

### 4.3 Gelecek Ã‡alÄ±ÅŸmalar

1. **Derin Ã–ÄŸrenme Entegrasyonu**:
   - LSTM/GRU ile temporal modelleme
   - Transformer tabanlÄ± sequence learning
   - End-to-end Ã¶ÄŸrenebilir sistem

2. **Ã‡oklu Modalite FÃ¼zyonu**:
   - RGB + Depth (RGB-D kameralar)
   - RGB + Termal kameralar
   - Video + IMU sensÃ¶r fÃ¼zyonu

3. **Adaptif EÅŸik Belirleme**:
   - KiÅŸiye Ã¶zel kalibrasyon
   - Ortam koÅŸullarÄ±na gÃ¶re ayarlama
   - Online learning ile eÅŸik optimizasyonu

4. **Okluzyona DayanÄ±klÄ±lÄ±k**:
   - KÄ±smi gÃ¶zlem tamamlama
   - Ã‡oklu kamera sistemi
   - Attention mekanizmalarÄ±

5. **DÃ¼ÅŸme SonrasÄ± Analiz**:
   - DÃ¼ÅŸme ciddiyeti sÄ±nÄ±flandÄ±rmasÄ±
   - Yaralanma riski tahmini
   - Kalkmaya Ã§alÄ±ÅŸma tespiti

6. **GerÃ§ek ZamanlÄ± UyarÄ± Sistemi**:
    - Bulut tabanlÄ± bildirim
    - SMS/Email entegrasyonu
    - Acil durum servisleri ile baÄŸlantÄ±

---

## TeÅŸekkÃ¼r

Bu projede aÅŸaÄŸÄ±daki aÃ§Ä±k kaynak teknolojilerden yararlanÄ±lmÄ±ÅŸtÄ±r:

* MediaPipe
* YOLOv8 (Ultralytics)
* OpenCV
* Streamlit

---

[1] World Health Organization. (2021). *Falls*. Retrieved from https://www.who.int/news-room/fact-sheets/detail/falls

[2] Centers for Disease Control and Prevention. (2020). *Important Facts about Falls*. Retrieved from https://www.cdc.gov/falls/facts.html

[3] Zigel, Y., Litvak, D., & Gannot, I. (2009). A method for automatic fall detection of elderly people using floor vibrations and soundâ€”proof of concept on human mimicking doll falls. *IEEE Transactions on Biomedical Engineering*, 56(12), 2858-2867.

[4] Bourke, A. K., O'Brien, J. V., & Lyons, G. M. (2007). Evaluation of a threshold-based tri-axial accelerometer fall detection algorithm. *Gait & Posture*, 26(2), 194-199.

[5] Liu, L., Popescu, M., Skubic, M., Rantz, M., Yardibi, T., & Cuddihy, P. (2011). Automatic fall detection based on Doppler radar motion signature. In *2011 5th International Conference on Pervasive Computing Technologies for Healthcare* (pp. 222-225). IEEE.

[6] Rougier, C., Meunier, J., St-Arnaud, A., & Rousseau, J. (2011). Robust video surveillance for fall detection based on human shape deformation. *IEEE Transactions on Circuits and Systems for Video Technology*, 21(5), 611-622.

[7] Vishwakarma, V., Mandal, C., & Sural, S. (2019). Automatic detection of human fall in video. In *Pattern Recognition and Machine Intelligence* (pp. 616-623). Springer.

[8] Lugaresi, C., Tang, J., Nash, H., McClanahan, C., Uboweja, E., Hays, M., ... & Grundmann, M. (2019). MediaPipe: A framework for building perception pipelines. *arXiv preprint arXiv:1906.08172*.

[9] Bazarevsky, V., Grishchenko, I., Raveendran, K., Zhu, T., Zhang, F., & Grundmann, M. (2020). BlazePose: On-device real-time body pose tracking. *arXiv preprint arXiv:2006.10204*.

[10] Jocher, G., Chaurasia, A., & Qiu, J. (2023). *Ultralytics YOLOv8*. Retrieved from https://github.com/ultralytics/ultralytics

---

## Ekler

### Ek A: Anahtar Nokta Ä°ndeksleri

#### MediaPipe 33 Keypoints
```
0: Burun
1: Sol gÃ¶z (iÃ§)
2: Sol gÃ¶z
3: Sol gÃ¶z (dÄ±ÅŸ)
4: SaÄŸ gÃ¶z (iÃ§)
5: SaÄŸ gÃ¶z
6: SaÄŸ gÃ¶z (dÄ±ÅŸ)
7: Sol kulak
8: SaÄŸ kulak
9: AÄŸÄ±z (sol)
10: AÄŸÄ±z (saÄŸ)
11: Sol omuz
12: SaÄŸ omuz
13: Sol dirsek
14: SaÄŸ dirsek
15: Sol bilek
16: SaÄŸ bilek
17: Sol el parmaÄŸÄ±
18: SaÄŸ el parmaÄŸÄ±
19: Sol el baÅŸparmak
20: SaÄŸ el baÅŸparmak
21: Sol el iÅŸaret parmaÄŸÄ±
22: SaÄŸ el iÅŸaret parmaÄŸÄ±
23: Sol kalÃ§a
24: SaÄŸ kalÃ§a
25: Sol diz
26: SaÄŸ diz
27: Sol ayak bileÄŸi
28: SaÄŸ ayak bileÄŸi
29: Sol topuk
30: SaÄŸ topuk
31: Sol ayak parmaÄŸÄ±
32: SaÄŸ ayak parmaÄŸÄ±
```

#### YOLOv8 COCO 17 Keypoints
```
0: Burun
1: Sol gÃ¶z
2: SaÄŸ gÃ¶z
3: Sol kulak
4: SaÄŸ kulak
5: Sol omuz
6: SaÄŸ omuz
7: Sol dirsek
8: SaÄŸ dirsek
9: Sol bilek
10: SaÄŸ bilek
11: Sol kalÃ§a
12: SaÄŸ kalÃ§a
13: Sol diz
14: SaÄŸ diz
15: Sol ayak bileÄŸi
16: SaÄŸ ayak bileÄŸi
```

### Ek B: Sistem Gereksinimleri DetayÄ±

#### Minimum Gereksinimler
- **CPU**: Intel Core i5-8250U / AMD Ryzen 5 2500U
- **RAM**: 8 GB DDR4
- **Depolama**: 2 GB SSD
- **GPU**: Entegre grafik (Intel UHD 620)
- **Ä°ÅŸletim Sistemi**: Windows 10 / Ubuntu 20.04
- **Python**: 3.11+

#### Ã–nerilen Gereksinimler
- **CPU**: Intel Core i7-10750H / AMD Ryzen 7 4800H
- **RAM**: 16 GB DDR4-2933
- **Depolama**: 10 GB NVMe SSD
- **GPU**: NVIDIA GTX 1650 (4 GB) / RTX 3050
- **Ä°ÅŸletim Sistemi**: Windows 11 / Ubuntu 22.04
- **Python**: 3.11.9

### Ek C: Kod YapÄ±sÄ±

```
fall-detection-system/
â”‚
â”œâ”€â”€ app_fast.py                 # Ana Streamlit uygulamasÄ±
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ fall_detector.py        # DÃ¼ÅŸme tespit algoritmasÄ±
â”‚   â”œâ”€â”€ pose_estimator.py       # MediaPipe pose estimation
â”‚   â”œâ”€â”€ multi_person_detector.py# YOLOv8 multi-person detection
â”‚   â””â”€â”€ video_url_handler.py    # Video giriÅŸ yÃ¶netimi
â”‚
â”œâ”€â”€ Fall/
â”‚   â”œâ”€â”€ Keypoints_CSV/          # DÃ¼ÅŸme keypoint verileri
â”‚   â””â”€â”€ Raw_Video/              # DÃ¼ÅŸme videolarÄ±
â”‚
â”œâ”€â”€ No_Fall/
â”‚   â”œâ”€â”€ Keypoints_CSV/          # Normal aktivite keypoints
â”‚   â””â”€â”€ Raw_Video/              # Normal aktivite videolarÄ±
â”‚
â”œâ”€â”€ requirements.txt            # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ README.md                   # KullanÄ±cÄ± dokÃ¼mantasyonu
â”œâ”€â”€ README_ACADEMIC.md          # Akademik dokÃ¼mantasyon
â””â”€â”€ yolov8n-pose.pt            # YOLOv8 Nano model weights
```

---

## Ä°letiÅŸim

**Proje Sahibi**: Fall Detection System Team
**Email**: ka5898522@gmail.com
**GitHub**: https://github.com/comandoo-cell/fall-detection-system
**Tarih**: AralÄ±k 2025

---

## AlÄ±ntÄ± / Citation

Bu projeyi araÅŸtÄ±rmanÄ±zda kullandÄ±ysanÄ±z, lÃ¼tfen ÅŸu ÅŸekilde alÄ±ntÄ± yapÄ±n:

### BibTeX
```bibtex
@software{fall_detection_system_2025,
  author       = {Fall Detection System Team},
  title        = {GerÃ§ek ZamanlÄ± DÃ¼ÅŸme Tespit Sistemi: Ã‡ok Kriterli Pose Estimation YaklaÅŸÄ±mÄ±},
    year         = {2025},
  month        = {12},
  url          = {https://github.com/comandoo-cell/fall-detection-system},
  version      = {1.0.0},
  note         = {MediaPipe ve YOLOv8 tabanlÄ± gerÃ§ek zamanlÄ± dÃ¼ÅŸme tespit sistemi}
}
```

### APA Format
```
Fall Detection System Team. (2025). GerÃ§ek ZamanlÄ± DÃ¼ÅŸme Tespit Sistemi: 
Ã‡ok Kriterli Pose Estimation YaklaÅŸÄ±mÄ± (Versiyon 1.0.0) [Bilgisayar yazÄ±lÄ±mÄ±]. 
GitHub. https://github.com/comandoo-cell/fall-detection-system
```

### IEEE Format
```
Fall Detection System Team, "GerÃ§ek ZamanlÄ± DÃ¼ÅŸme Tespit Sistemi: Ã‡ok Kriterli 
Pose Estimation YaklaÅŸÄ±mÄ±," 2025. [Online]. Available: 
https://github.com/comandoo-cell/fall-detection-system
```

### Chicago Format
```
Fall Detection System Team. 2025. "GerÃ§ek ZamanlÄ± DÃ¼ÅŸme Tespit Sistemi: 
Ã‡ok Kriterli Pose Estimation YaklaÅŸÄ±mÄ±." Version 1.0.0. 
https://github.com/comandoo-cell/fall-detection-system.
```

---

## KatkÄ± Yapanlar / Contributors

Bu projeye katkÄ±da bulunan herkese teÅŸekkÃ¼r ederiz.

**Ana GeliÅŸtiriciler**:
- Fall Detection System Team

**Ã–zel TeÅŸekkÃ¼rler**:
- MediaPipe Team (Google)
- Ultralytics YOLOv8 Team
- OpenCV Community
- Streamlit Team

---

<div align="center">

**Bu akademik dokÃ¼mantasyon, gerÃ§ek zamanlÄ± dÃ¼ÅŸme tespit sistemi projesinin teknik ve bilimsel detaylarÄ±nÄ± iÃ§ermektedir.**

**â­ AraÅŸtÄ±rmanÄ±zda kullandÄ±ysanÄ±z lÃ¼tfen alÄ±ntÄ± yapÄ±n! â­**

[![GitHub](https://img.shields.io/badge/GitHub-comandoo--cell%2Ffall--detection--system-blue?logo=github)](https://github.com/comandoo-cell/fall-detection-system)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](../LICENSE)
[![DOI](https://img.shields.io/badge/DOI-Beklemede-orange)]()

</div>
>>>>>>> e852b17 (docs: akademik raporda duzeltmeler)
